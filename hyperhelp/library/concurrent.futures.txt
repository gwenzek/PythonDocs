%hyperhelp title="concurrent.futures" date="2021-07-11"
*|module-concurrent.futures:⚓|*

New in version 3.2.

*Source code:* |:github.com/python/cpython/tree/3.8/Lib/concurrent/futures/thread.py:Lib/concurrent/futures/thread.py| and
|:github.com/python/cpython/tree/3.8/Lib/concurrent/futures/process.py:Lib/concurrent/futures/process.py|

======================================================================

The |:module-concurrent.futures:concurrent.futures| module provides a high-level interface for
asynchronously executing callables.

The asynchronous execution can be performed with threads, using
|:concurrent.futures.ThreadPoolExecutor:ThreadPoolExecutor|, or separate processes, using |:concurrent.futures.ProcessPoolExecutor:ProcessPoolExecutor|.  Both
implement the same interface, which is defined by the abstract |:concurrent.futures.Executor:Executor| class.

# executor-objects:Executor Objects

*concurrent.futures.Executor:class concurrent.futures.Executor*

   An abstract class that provides methods to execute calls asynchronously.  It
   should not be used directly, but through its concrete subclasses.

      *concurrent.futures.Executor.submit:submit(fn, *args, **kwargs)*

         Schedules the callable, *fn*, to be executed as "fn(*args **kwargs)" and returns
         a |:concurrent.futures.Future:Future| object representing the execution of the callable.

```rst
with ThreadPoolExecutor(max_workers=1) as executor:
    future = executor.submit(pow, 323, 1235)
    print(future.result())
```

      *concurrent.futures.Executor.map:map(func, *iterables, timeout=None, chunksize=1)*

         Similar to |:library/functions.txt/map:map(func, *iterables)| except:

         * the *iterables* are collected immediately rather than lazily;

         * *func* is executed asynchronously and several calls to *func* may be made
           concurrently.

         The returned iterator raises a |:concurrent.futures.TimeoutError:concurrent.futures.TimeoutError| if |:library/stdtypes.txt/iterator.__next__:__next__()|
         is called and the result isn’t available after *timeout* seconds from the
         original call to |:concurrent.futures.Executor.map:Executor.map()|. *timeout* can be an int or a float.  If *
         timeout* is not specified or "None", there is no limit to the wait time.

         If a *func* call raises an exception, then that exception will be raised when
         its value is retrieved from the iterator.

         When using |:concurrent.futures.ProcessPoolExecutor:ProcessPoolExecutor|, this method chops *iterables* into a number of
         chunks which it submits to the pool as separate tasks.  The (approximate) size
         of these chunks can be specified by setting *chunksize* to a positive integer.
         For very long iterables, using a large value for *chunksize* can significantly
         improve performance compared to the default size of 1.  With
         |:concurrent.futures.ThreadPoolExecutor:ThreadPoolExecutor|, *chunksize* has no effect.

         Changed in version 3.5: Added the *chunksize* argument.

      *concurrent.futures.Executor.shutdown:shutdown(wait=True)*

         Signal the executor that it should free any resources that it is using when the
         currently pending futures are done executing.  Calls to |:concurrent.futures.Executor.submit:Executor.submit()| and
         |:concurrent.futures.Executor.map:Executor.map()| made after shutdown will raise |:library/exceptions.txt/RuntimeError:RuntimeError|.

         If *wait* is "True" then this method will not return until all the pending
         futures are done executing and the resources associated with the executor have
         been freed.  If *wait* is "False" then this method will return immediately and
         the resources associated with the executor will be freed when all pending
         futures are done executing.  Regardless of the value of *wait*, the entire
         Python program will not exit until all pending futures are done executing.

         You can avoid having to call this method explicitly if you use the |:reference/compound_stmts.txt/with:with|
         statement, which will shutdown the |:concurrent.futures.Executor:Executor| (waiting as if
         |:concurrent.futures.Executor.shutdown:Executor.shutdown()| were called with *wait* set to "True"):

```rst
import shutil
with ThreadPoolExecutor(max_workers=4) as e:
    e.submit(shutil.copy, 'src1.txt', 'dest1.txt')
    e.submit(shutil.copy, 'src2.txt', 'dest2.txt')
    e.submit(shutil.copy, 'src3.txt', 'dest3.txt')
    e.submit(shutil.copy, 'src4.txt', 'dest4.txt')
```

# threadpoolexecutor:ThreadPoolExecutor

|:concurrent.futures.ThreadPoolExecutor:ThreadPoolExecutor| is an |:concurrent.futures.Executor:Executor| subclass that uses a pool of threads to
execute calls asynchronously.

Deadlocks can occur when the callable associated with a |:concurrent.futures.Future:Future| waits on the
results of another |:concurrent.futures.Future:Future|.  For example:

```rst
import time
def wait_on_b():
    time.sleep(5)
    print(b.result())  # b will never complete because it is waiting on a.
    return 5

def wait_on_a():
    time.sleep(5)
    print(a.result())  # a will never complete because it is waiting on b.
    return 6


executor = ThreadPoolExecutor(max_workers=2)
a = executor.submit(wait_on_b)
b = executor.submit(wait_on_a)
```

And:

```rst
def wait_on_future():
    f = executor.submit(pow, 5, 2)
    # This will never complete because there is only one worker thread and
    # it is executing this function.
    print(f.result())

executor = ThreadPoolExecutor(max_workers=1)
executor.submit(wait_on_future)
```

*concurrent.futures.ThreadPoolExecutor:class concurrent.futures.ThreadPoolExecutor(max_workers=None, thread_name_prefix='', initializer=None, initargs=())*

   An |:concurrent.futures.Executor:Executor| subclass that uses a pool of at most *max_workers* threads to
   execute calls asynchronously.

   *initializer* is an optional callable that is called at the start of each worker
   thread; *initargs* is a tuple of arguments passed to the initializer.  Should *
   initializer* raise an exception, all currently pending jobs will raise a
   |:concurrent.futures.thread.BrokenThreadPool:BrokenThreadPool|, as well as any attempt to submit more jobs to the pool.

   Changed in version 3.5: If *max_workers* is "None" or not given, it will default
   to the number of processors on the machine, multiplied by "5", assuming that
   |:concurrent.futures.ThreadPoolExecutor:ThreadPoolExecutor| is often used to overlap I/O instead of CPU work and the
   number of workers should be higher than the number of workers for
   |:concurrent.futures.ProcessPoolExecutor:ProcessPoolExecutor|.

   New in version 3.6: The *thread_name_prefix* argument was added to allow users
   to control the |:library/threading.txt/threading.Thread:threading.Thread| names for worker threads created by the pool
   for easier debugging.

   Changed in version 3.7: Added the *initializer* and *initargs* arguments.

   Changed in version 3.8: Default value of *max_workers* is changed to "min(32,
   os.cpu_count() + 4)". This default value preserves at least 5 workers for I/O
   bound tasks. It utilizes at most 32 CPU cores for CPU bound tasks which release
   the GIL. And it avoids using very large resources implicitly on many-core
   machines.ThreadPoolExecutor now reuses idle worker threads before starting *
   max_workers* worker threads too.

## threadpoolexecutor-example:ThreadPoolExecutor Example

```rst
import concurrent.futures
import urllib.request

URLS = ['http://www.foxnews.com/',
        'http://www.cnn.com/',
        'http://europe.wsj.com/',
        'http://www.bbc.co.uk/',
        'http://some-made-up-domain.com/']

# Retrieve a single page and report the URL and contents
def load_url(url, timeout):
    with urllib.request.urlopen(url, timeout=timeout) as conn:
        return conn.read()

# We can use a with statement to ensure threads are cleaned up promptly
with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
    # Start the load operations and mark each future with its URL
    future_to_url = {executor.submit(load_url, url, 60): url for url in URLS}
    for future in concurrent.futures.as_completed(future_to_url):
        url = future_to_url[future]
        try:
            data = future.result()
        except Exception as exc:
            print('%r generated an exception: %s' % (url, exc))
        else:
            print('%r page is %d bytes' % (url, len(data)))
```

# processpoolexecutor:ProcessPoolExecutor

The |:concurrent.futures.ProcessPoolExecutor:ProcessPoolExecutor| class is an |:concurrent.futures.Executor:Executor| subclass that uses a pool of
processes to execute calls asynchronously. |:concurrent.futures.ProcessPoolExecutor:ProcessPoolExecutor| uses the
|:library/multiprocessing.txt/module-multiprocessing:multiprocessing| module, which allows it to side-step the
|:glossary.txt/term-global-interpreter-lock:Global Interpreter Lock| but also means that only picklable objects can be
executed and returned.

The "__main__" module must be importable by worker subprocesses. This means that
|:concurrent.futures.ProcessPoolExecutor:ProcessPoolExecutor| will not work in the interactive interpreter.

Calling |:concurrent.futures.Executor:Executor| or |:concurrent.futures.Future:Future| methods from a callable submitted to a
|:concurrent.futures.ProcessPoolExecutor:ProcessPoolExecutor| will result in deadlock.

*concurrent.futures.ProcessPoolExecutor:class concurrent.futures.ProcessPoolExecutor(max_workers=None, mp_context=None, initializer=None, initargs=())*

   An |:concurrent.futures.Executor:Executor| subclass that executes calls asynchronously using a pool of at
   most *max_workers* processes.  If *max_workers* is "None" or not given, it will
   default to the number of processors on the machine. If *max_workers* is less
   than or equal to "0", then a |:library/exceptions.txt/ValueError:ValueError| will be raised. On Windows, *
   max_workers* must be less than or equal to "61". If it is not then |:library/exceptions.txt/ValueError:ValueError|
   will be raised. If *max_workers* is "None", then the default chosen will be at
   most "61", even if more processors are available. *mp_context* can be a
   multiprocessing context or None. It will be used to launch the workers. If *
   mp_context* is "None" or not given, the default multiprocessing context is used.

   *initializer* is an optional callable that is called at the start of each worker
   process; *initargs* is a tuple of arguments passed to the initializer.  Should *
   initializer* raise an exception, all currently pending jobs will raise a
   |:concurrent.futures.process.BrokenProcessPool:BrokenProcessPool|, as well as any attempt to submit more jobs to the pool.

   Changed in version 3.3: When one of the worker processes terminates abruptly, a
   "BrokenProcessPool" error is now raised.  Previously, behaviour was undefined
   but operations on the executor or its futures would often freeze or deadlock.

   Changed in version 3.7: The *mp_context* argument was added to allow users to
   control the start_method for worker processes created by the pool.Added the *
   initializer* and *initargs* arguments.

## processpoolexecutor-example:ProcessPoolExecutor Example

```rst
import concurrent.futures
import math

PRIMES = [
    112272535095293,
    112582705942171,
    112272535095293,
    115280095190773,
    115797848077099,
    1099726899285419]

def is_prime(n):
    if n < 2:
        return False
    if n == 2:
        return True
    if n % 2 == 0:
        return False

    sqrt_n = int(math.floor(math.sqrt(n)))
    for i in range(3, sqrt_n + 1, 2):
        if n % i == 0:
            return False
    return True

def main():
    with concurrent.futures.ProcessPoolExecutor() as executor:
        for number, prime in zip(PRIMES, executor.map(is_prime, PRIMES)):
            print('%d is prime: %s' % (number, prime))

if __name__ == '__main__':
    main()
```

# future-objects:Future Objects

The |:concurrent.futures.Future:Future| class encapsulates the asynchronous execution of a callable.
|:concurrent.futures.Future:Future| instances are created by |:concurrent.futures.Executor.submit:Executor.submit()|.

*concurrent.futures.Future:class concurrent.futures.Future*

   Encapsulates the asynchronous execution of a callable.  |:concurrent.futures.Future:Future| instances are
   created by |:concurrent.futures.Executor.submit:Executor.submit()| and should not be created directly except for
   testing.

      *concurrent.futures.Future.cancel:cancel()*

         Attempt to cancel the call.  If the call is currently being executed or finished
         running and cannot be cancelled then the method will return "False", otherwise
         the call will be cancelled and the method will return "True".

      *concurrent.futures.Future.cancelled:cancelled()*

         Return "True" if the call was successfully cancelled.

      *concurrent.futures.Future.running:running()*

         Return "True" if the call is currently being executed and cannot be cancelled.

      *concurrent.futures.Future.done:done()*

         Return "True" if the call was successfully cancelled or finished running.

      *concurrent.futures.Future.result:result(timeout=None)*

         Return the value returned by the call. If the call hasn’t yet completed then
         this method will wait up to *timeout* seconds.  If the call hasn’t completed in
         *timeout* seconds, then a |:concurrent.futures.TimeoutError:concurrent.futures.TimeoutError| will be raised. *
         timeout* can be an int or float.  If *timeout* is not specified or "None", there
         is no limit to the wait time.

         If the future is cancelled before completing then |:concurrent.futures.CancelledError:CancelledError| will be
         raised.

         If the call raised, this method will raise the same exception.

      *concurrent.futures.Future.exception:exception(timeout=None)*

         Return the exception raised by the call.  If the call hasn’t yet completed then
         this method will wait up to *timeout* seconds.  If the call hasn’t completed in
         *timeout* seconds, then a |:concurrent.futures.TimeoutError:concurrent.futures.TimeoutError| will be raised.  *
         timeout* can be an int or float.  If *timeout* is not specified or "None", there
         is no limit to the wait time.

         If the future is cancelled before completing then |:concurrent.futures.CancelledError:CancelledError| will be
         raised.

         If the call completed without raising, "None" is returned.

      *concurrent.futures.Future.add_done_callback:add_done_callback(fn)*

         Attaches the callable *fn* to the future.  *fn* will be called, with the future
         as its only argument, when the future is cancelled or finishes running.

         Added callables are called in the order that they were added and are always
         called in a thread belonging to the process that added them.  If the callable
         raises an |:library/exceptions.txt/Exception:Exception| subclass, it will be logged and ignored.  If the callable
         raises a |:library/exceptions.txt/BaseException:BaseException| subclass, the behavior is undefined.

         If the future has already completed or been cancelled, *fn* will be called
         immediately.

   The following |:concurrent.futures.Future:Future| methods are meant for use in unit tests and |:concurrent.futures.Executor:Executor|
   implementations.

      *concurrent.futures.Future.set_running_or_notify_cancel:set_running_or_notify_cancel()*

         This method should only be called by |:concurrent.futures.Executor:Executor| implementations before executing
         the work associated with the |:concurrent.futures.Future:Future| and by unit tests.

         If the method returns "False" then the |:concurrent.futures.Future:Future| was cancelled, i.e.
         |:concurrent.futures.Future.cancel:Future.cancel()| was called and returned *True*.  Any threads waiting on the
         |:concurrent.futures.Future:Future| completing (i.e. through |:concurrent.futures.as_completed:as_completed()| or |:concurrent.futures.wait:wait()|) will be woken
         up.

         If the method returns "True" then the |:concurrent.futures.Future:Future| was not cancelled and has been
         put in the running state, i.e. calls to |:concurrent.futures.Future.running:Future.running()| will return *True*.

         This method can only be called once and cannot be called after
         |:concurrent.futures.Future.set_result:Future.set_result()| or |:concurrent.futures.Future.set_exception:Future.set_exception()| have been called.

      *concurrent.futures.Future.set_result:set_result(result)*

         Sets the result of the work associated with the |:concurrent.futures.Future:Future| to *result*.

         This method should only be used by |:concurrent.futures.Executor:Executor| implementations and unit tests.

         Changed in version 3.8: This method raises
         |:concurrent.futures.InvalidStateError:concurrent.futures.InvalidStateError| if the |:concurrent.futures.Future:Future| is already done.

      *concurrent.futures.Future.set_exception:set_exception(exception)*

         Sets the result of the work associated with the |:concurrent.futures.Future:Future| to the |:library/exceptions.txt/Exception:Exception| *
         exception*.

         This method should only be used by |:concurrent.futures.Executor:Executor| implementations and unit tests.

         Changed in version 3.8: This method raises
         |:concurrent.futures.InvalidStateError:concurrent.futures.InvalidStateError| if the |:concurrent.futures.Future:Future| is already done.

# module-functions:Module Functions

*concurrent.futures.wait:concurrent.futures.wait(fs, timeout=None, return_when=ALL_COMPLETED)*

   Wait for the |:concurrent.futures.Future:Future| instances (possibly created by different |:concurrent.futures.Executor:Executor|
   instances) given by *fs* to complete.  Returns a named 2-tuple of sets.  The
   first set, named "done", contains the futures that completed (finished or
   cancelled futures) before the wait completed.  The second set, named "not_done",
   contains the futures that did not complete (pending or running futures).

   *timeout* can be used to control the maximum number of seconds to wait before
   returning.  *timeout* can be an int or float.  If *timeout* is not specified or
   "None", there is no limit to the wait time.

   *return_when* indicates when this function should return.  It must be one of the
   following constants:

   +-------------------------------+------------------------------------------+
   | Constant                      | Description                              |
   |===============================|==========================================|
   | "FIRST_COMPLETED"             | The function will return when any future |
   |                               | finishes or is cancelled.                |
   +-------------------------------+------------------------------------------+
   | "FIRST_EXCEPTION"             | The function will return when any future |
   |                               | finishes by raising an exception.  If no |
   |                               | future raises an exception then it is    |
   |                               | equivalent to "ALL_COMPLETED".           |
   +-------------------------------+------------------------------------------+
   | "ALL_COMPLETED"               | The function will return when all        |
   |                               | futures finish or are cancelled.         |
   +-------------------------------+------------------------------------------+

*concurrent.futures.as_completed:concurrent.futures.as_completed(fs, timeout=None)*

   Returns an iterator over the |:concurrent.futures.Future:Future| instances (possibly created by different
   |:concurrent.futures.Executor:Executor| instances) given by *fs* that yields futures as they complete
   (finished or cancelled futures). Any futures given by *fs* that are duplicated
   will be returned once. Any futures that completed before |:concurrent.futures.as_completed:as_completed()| is
   called will be yielded first.  The returned iterator raises a
   |:concurrent.futures.TimeoutError:concurrent.futures.TimeoutError| if |:library/stdtypes.txt/iterator.__next__:__next__()| is called and the result isn’t
   available after *timeout* seconds from the original call to |:concurrent.futures.as_completed:as_completed()|.  *
   timeout* can be an int or float. If *timeout* is not specified or "None", there
   is no limit to the wait time.

See also:

  *|index-0:⚓|*
  |:www.python.org/dev/peps/pep-3148:PEP 3148| – futures - execute computations asynchronously
     The proposal which described this feature for inclusion in the Python standard
     library.

# exception-classes:Exception classes

*concurrent.futures.CancelledError:exception concurrent.futures.CancelledError*

   Raised when a future is cancelled.

*concurrent.futures.TimeoutError:exception concurrent.futures.TimeoutError*

   Raised when a future operation exceeds the given timeout.

*concurrent.futures.BrokenExecutor:exception concurrent.futures.BrokenExecutor*

   Derived from |:library/exceptions.txt/RuntimeError:RuntimeError|, this exception class is raised when an executor is
   broken for some reason, and cannot be used to submit or execute new tasks.

   New in version 3.7.

*concurrent.futures.InvalidStateError:exception concurrent.futures.InvalidStateError*

   Raised when an operation is performed on a future that is not allowed in the
   current state.

   New in version 3.8.

*concurrent.futures.thread.BrokenThreadPool:exception concurrent.futures.thread.BrokenThreadPool*

   Derived from |:concurrent.futures.BrokenExecutor:BrokenExecutor|, this exception class is raised when one of the
   workers of a "ThreadPoolExecutor" has failed initializing.

   New in version 3.7.

*concurrent.futures.process.BrokenProcessPool:exception concurrent.futures.process.BrokenProcessPool*

   Derived from |:concurrent.futures.BrokenExecutor:BrokenExecutor| (formerly |:library/exceptions.txt/RuntimeError:RuntimeError|), this exception class is
   raised when one of the workers of a "ProcessPoolExecutor" has terminated in a
   non-clean fashion (for example, if it was killed from the outside).

   New in version 3.3.



