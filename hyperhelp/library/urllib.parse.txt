%hyperhelp title="urllib.parse" date="2021-07-11"
*|module-urllib.parse:⚓|*

*Source code:* |:github.com/python/cpython/tree/3.8/Lib/urllib/parse.py:Lib/urllib/parse.py|

*|index-0:⚓|*

======================================================================

This module defines a standard interface to break Uniform Resource Locator (URL)
strings up in components (addressing scheme, network location, path etc.), to
combine the components back into a URL string, and to convert a “relative URL”
to an absolute URL given a “base URL.”

The module has been designed to match the Internet RFC on Relative Uniform
Resource Locators. It supports the following URL schemes: "file", "ftp", "gopher
", "hdl", "http", "https", "imap", "mailto", "mms", "news", "nntp", "prospero",
"rsync", "rtsp", "rtspu", "sftp", "shttp", "sip", "sips", "snews", "svn", "
svn+ssh", "telnet", "wais", "ws", "wss".

The |:module-urllib.parse:urllib.parse| module defines functions that fall into two broad categories:
URL parsing and URL quoting. These are covered in detail in the following
sections.

# url-parsing:URL Parsing

The URL parsing functions focus on splitting a URL string into its components,
or on combining URL components into a URL string.

*urllib.parse.urlparse:urllib.parse.urlparse(urlstring, scheme='', allow_fragments=True)*

   Parse a URL into six components, returning a 6-item |:glossary.txt/term-named-tuple:named tuple|.  This
   corresponds to the general structure of a URL: "
   scheme://netloc/path;parameters?query#fragment". Each tuple item is a string,
   possibly empty. The components are not broken up in smaller parts (for example,
   the network location is a single string), and % escapes are not expanded. The
   delimiters as shown above are not part of the result, except for a leading slash
   in the *path* component, which is retained if present.  For example:

```python
>>> from urllib.parse import urlparse
>>> o = urlparse('http://www.cwi.nl:80/%7Eguido/Python.html')
>>> o   
ParseResult(scheme='http', netloc='www.cwi.nl:80', path='/%7Eguido/Python.html',
            params='', query='', fragment='')
>>> o.scheme
'http'
>>> o.port
80
>>> o.geturl()
'http://www.cwi.nl:80/%7Eguido/Python.html'
```

   Following the syntax specifications in *|index-1:⚓|* |:tools.ietf.org/html/rfc1808.html:RFC 1808|, urlparse
   recognizes a netloc only if it is properly introduced by ‘//’.  Otherwise the
   input is presumed to be a relative URL and thus to start with a path component.

```rst
>>> from urllib.parse import urlparse
>>> urlparse('//www.cwi.nl:80/%7Eguido/Python.html')
ParseResult(scheme='', netloc='www.cwi.nl:80', path='/%7Eguido/Python.html',
            params='', query='', fragment='')
>>> urlparse('www.cwi.nl/%7Eguido/Python.html')
ParseResult(scheme='', netloc='', path='www.cwi.nl/%7Eguido/Python.html',
            params='', query='', fragment='')
>>> urlparse('help/Python.html')
ParseResult(scheme='', netloc='', path='help/Python.html', params='',
            query='', fragment='')
```

   The *scheme* argument gives the default addressing scheme, to be used only if
   the URL does not specify one.  It should be the same type (text or bytes) as *
   urlstring*, except that the default value "''" is always allowed, and is
   automatically converted to "b''" if appropriate.

   If the *allow_fragments* argument is false, fragment identifiers are not
   recognized.  Instead, they are parsed as part of the path, parameters or query
   component, and "fragment" is set to the empty string in the return value.

   The return value is a |:glossary.txt/term-named-tuple:named tuple|, which means that its items can be accessed
   by index or as named attributes, which are:

   +--------------------+---------+----------------------------+------------------------+
   | Attribute          | Index   | Value                      | Value if not present   |
   |====================|=========|============================|========================|
   | "scheme"           | 0       | URL scheme specifier       | *scheme* parameter     |
   +--------------------+---------+----------------------------+------------------------+
   | "netloc"           | 1       | Network location part      | empty string           |
   +--------------------+---------+----------------------------+------------------------+
   | "path"             | 2       | Hierarchical path          | empty string           |
   +--------------------+---------+----------------------------+------------------------+
   | "params"           | 3       | Parameters for last path   | empty string           |
   |                    |         | element                    |                        |
   +--------------------+---------+----------------------------+------------------------+
   | "query"            | 4       | Query component            | empty string           |
   +--------------------+---------+----------------------------+------------------------+
   | "fragment"         | 5       | Fragment identifier        | empty string           |
   +--------------------+---------+----------------------------+------------------------+
   | "username"         |         | User name                  | |:library/constants.t  |
   |                    |         |                            | xt/None:None|          |
   +--------------------+---------+----------------------------+------------------------+
   | "password"         |         | Password                   | |:library/constants.t  |
   |                    |         |                            | xt/None:None|          |
   +--------------------+---------+----------------------------+------------------------+
   | "hostname"         |         | Host name (lower case)     | |:library/constants.t  |
   |                    |         |                            | xt/None:None|          |
   +--------------------+---------+----------------------------+------------------------+
   | "port"             |         | Port number as integer, if | |:library/constants.t  |
   |                    |         | present                    | xt/None:None|          |
   +--------------------+---------+----------------------------+------------------------+

   Reading the "port" attribute will raise a |:library/exceptions.txt/ValueError:ValueError| if an invalid port is
   specified in the URL.  See section |:urlparse-result-object:Structured Parse Results| for more
   information on the result object.

   Unmatched square brackets in the "netloc" attribute will raise a |:library/exceptions.txt/ValueError:ValueError|.

   Characters in the "netloc" attribute that decompose under NFKC normalization (as
   used by the IDNA encoding) into any of "/", "?", "#", "@", or ":" will raise a
   |:library/exceptions.txt/ValueError:ValueError|. If the URL is decomposed before parsing, no error will be raised.

   As is the case with all named tuples, the subclass has a few additional methods
   and attributes that are particularly useful. One such method is "_replace()".
   The "_replace()" method will return a new ParseResult object replacing specified
   fields with new values.

```rst
>>> from urllib.parse import urlparse
>>> u = urlparse('//www.cwi.nl:80/%7Eguido/Python.html')
>>> u
ParseResult(scheme='', netloc='www.cwi.nl:80', path='/%7Eguido/Python.html',
            params='', query='', fragment='')
>>> u._replace(scheme='http')
ParseResult(scheme='http', netloc='www.cwi.nl:80', path='/%7Eguido/Python.html',
            params='', query='', fragment='')
```

   Changed in version 3.2: Added IPv6 URL parsing capabilities.

   Changed in version 3.3: The fragment is now parsed for all URL schemes (unless *
   allow_fragment* is false), in accordance with *|index-2:⚓|* |:tools.ietf.org/html/rfc3986.html:RFC 3986|.
   Previously, a whitelist of schemes that support fragments existed.

   Changed in version 3.6: Out-of-range port numbers now raise |:library/exceptions.txt/ValueError:ValueError|,
   instead of returning |:library/constants.txt/None:None|.

   Changed in version 3.8: Characters that affect netloc parsing under NFKC
   normalization will now raise |:library/exceptions.txt/ValueError:ValueError|.

*urllib.parse.parse_qs:urllib.parse.parse_qs(qs, keep_blank_values=False, strict_parsing=False, encoding='utf-8', errors='replace', max_num_fields=None, separator='&')*

   Parse a query string given as a string argument (data of type *application/x
   -www-form-urlencoded*).  Data are returned as a dictionary.  The dictionary keys
   are the unique query variable names and the values are lists of values for each
   name.

   The optional argument *keep_blank_values* is a flag indicating whether blank
   values in percent-encoded queries should be treated as blank strings. A true
   value indicates that blanks should be retained as  blank strings.  The default
   false value indicates that blank values are to be ignored and treated as if they
   were not included.

   The optional argument *strict_parsing* is a flag indicating what to do with
   parsing errors.  If false (the default), errors are silently ignored.  If true,
   errors raise a |:library/exceptions.txt/ValueError:ValueError| exception.

   The optional *encoding* and *errors* parameters specify how to decode percent-
   encoded sequences into Unicode characters, as accepted by the |:library/stdtypes.txt/bytes.decode:bytes.decode()|
   method.

   The optional argument *max_num_fields* is the maximum number of fields to read.
   If set, then throws a |:library/exceptions.txt/ValueError:ValueError| if there are more than *max_num_fields*
   fields read.

   The optional argument *separator* is the symbol to use for separating the query
   arguments. It defaults to "&".

   Use the |:urllib.parse.urlencode:urllib.parse.urlencode()| function (with the "doseq" parameter set to "
   True") to convert such dictionaries into query strings.

   Changed in version 3.2: Add *encoding* and *errors* parameters.

   Changed in version 3.8: Added *max_num_fields* parameter.

   Changed in version 3.8.8: Added *separator* parameter with the default value of
   "&". Python versions earlier than Python 3.8.8 allowed using both ";" and "&" as
   query parameter separator. This has been changed to allow only a single
   separator key, with "&" as the default separator.

*urllib.parse.parse_qsl:urllib.parse.parse_qsl(qs, keep_blank_values=False, strict_parsing=False, encoding='utf-8', errors='replace', max_num_fields=None, separator='&')*

   Parse a query string given as a string argument (data of type *application/x
   -www-form-urlencoded*).  Data are returned as a list of name, value pairs.

   The optional argument *keep_blank_values* is a flag indicating whether blank
   values in percent-encoded queries should be treated as blank strings. A true
   value indicates that blanks should be retained as  blank strings.  The default
   false value indicates that blank values are to be ignored and treated as if they
   were not included.

   The optional argument *strict_parsing* is a flag indicating what to do with
   parsing errors.  If false (the default), errors are silently ignored.  If true,
   errors raise a |:library/exceptions.txt/ValueError:ValueError| exception.

   The optional *encoding* and *errors* parameters specify how to decode percent-
   encoded sequences into Unicode characters, as accepted by the |:library/stdtypes.txt/bytes.decode:bytes.decode()|
   method.

   The optional argument *max_num_fields* is the maximum number of fields to read.
   If set, then throws a |:library/exceptions.txt/ValueError:ValueError| if there are more than *max_num_fields*
   fields read.

   The optional argument *separator* is the symbol to use for separating the query
   arguments. It defaults to "&".

   Use the |:urllib.parse.urlencode:urllib.parse.urlencode()| function to convert such lists of pairs into
   query strings.

   Changed in version 3.2: Add *encoding* and *errors* parameters.

   Changed in version 3.8: Added *max_num_fields* parameter.

   Changed in version 3.8.8: Added *separator* parameter with the default value of
   "&". Python versions earlier than Python 3.8.8 allowed using both ";" and "&" as
   query parameter separator. This has been changed to allow only a single
   separator key, with "&" as the default separator.

*urllib.parse.urlunparse:urllib.parse.urlunparse(parts)*

   Construct a URL from a tuple as returned by "urlparse()". The *parts* argument
   can be any six-item iterable. This may result in a slightly different, but
   equivalent URL, if the URL that was parsed originally had unnecessary delimiters
   (for example, a "?" with an empty query; the RFC states that these are
   equivalent).

*urllib.parse.urlsplit:urllib.parse.urlsplit(urlstring, scheme='', allow_fragments=True)*

   This is similar to |:urllib.parse.urlparse:urlparse()|, but does not split the params from the URL.
   This should generally be used instead of |:urllib.parse.urlparse:urlparse()| if the more recent URL
   syntax allowing parameters to be applied to each segment of the *path* portion
   of the URL (see *|index-3:⚓|* |:tools.ietf.org/html/rfc2396.html:RFC 2396|) is wanted.  A separate function is
   needed to separate the path segments and parameters.  This function returns a
   5-item |:glossary.txt/term-named-tuple:named tuple|:

```rst
(addressing scheme, network location, path, query, fragment identifier).
```

   The return value is a |:glossary.txt/term-named-tuple:named tuple|, its items can be accessed by index or as
   named attributes:

   +--------------------+---------+---------------------------+------------------------+
   | Attribute          | Index   | Value                     | Value if not present   |
   |====================|=========|===========================|========================|
   | "scheme"           | 0       | URL scheme specifier      | *scheme* parameter     |
   +--------------------+---------+---------------------------+------------------------+
   | "netloc"           | 1       | Network location part     | empty string           |
   +--------------------+---------+---------------------------+------------------------+
   | "path"             | 2       | Hierarchical path         | empty string           |
   +--------------------+---------+---------------------------+------------------------+
   | "query"            | 3       | Query component           | empty string           |
   +--------------------+---------+---------------------------+------------------------+
   | "fragment"         | 4       | Fragment identifier       | empty string           |
   +--------------------+---------+---------------------------+------------------------+
   | "username"         |         | User name                 | |:library/constants.t  |
   |                    |         |                           | xt/None:None|          |
   +--------------------+---------+---------------------------+------------------------+
   | "password"         |         | Password                  | |:library/constants.t  |
   |                    |         |                           | xt/None:None|          |
   +--------------------+---------+---------------------------+------------------------+
   | "hostname"         |         | Host name (lower case)    | |:library/constants.t  |
   |                    |         |                           | xt/None:None|          |
   +--------------------+---------+---------------------------+------------------------+
   | "port"             |         | Port number as integer,   | |:library/constants.t  |
   |                    |         | if present                | xt/None:None|          |
   +--------------------+---------+---------------------------+------------------------+

   Reading the "port" attribute will raise a |:library/exceptions.txt/ValueError:ValueError| if an invalid port is
   specified in the URL.  See section |:urlparse-result-object:Structured Parse Results| for more
   information on the result object.

   Unmatched square brackets in the "netloc" attribute will raise a |:library/exceptions.txt/ValueError:ValueError|.

   Characters in the "netloc" attribute that decompose under NFKC normalization (as
   used by the IDNA encoding) into any of "/", "?", "#", "@", or ":" will raise a
   |:library/exceptions.txt/ValueError:ValueError|. If the URL is decomposed before parsing, no error will be raised.

   Changed in version 3.6: Out-of-range port numbers now raise |:library/exceptions.txt/ValueError:ValueError|,
   instead of returning |:library/constants.txt/None:None|.

   Changed in version 3.8: Characters that affect netloc parsing under NFKC
   normalization will now raise |:library/exceptions.txt/ValueError:ValueError|.

*urllib.parse.urlunsplit:urllib.parse.urlunsplit(parts)*

   Combine the elements of a tuple as returned by |:urllib.parse.urlsplit:urlsplit()| into a complete URL
   as a string. The *parts* argument can be any five-item iterable. This may result
   in a slightly different, but equivalent URL, if the URL that was parsed
   originally had unnecessary delimiters (for example, a ? with an empty query; the
   RFC states that these are equivalent).

*urllib.parse.urljoin:urllib.parse.urljoin(base, url, allow_fragments=True)*

   Construct a full (“absolute”) URL by combining a “base URL” (*base*) with
   another URL (*url*).  Informally, this uses components of the base URL, in
   particular the addressing scheme, the network location and (part of) the path,
   to provide missing components in the relative URL.  For example:

```python
>>> from urllib.parse import urljoin
>>> urljoin('http://www.cwi.nl/%7Eguido/Python.html', 'FAQ.html')
'http://www.cwi.nl/%7Eguido/FAQ.html'
```

   The *allow_fragments* argument has the same meaning and default as for
   |:urllib.parse.urlparse:urlparse()|.

   Note:

     If *url* is an absolute URL (that is, starting with "//" or "scheme://"), the *
     url*’s host name and/or scheme will be present in the result.  For example:

```rst
>>> urljoin('http://www.cwi.nl/%7Eguido/Python.html',
...         '//www.python.org/%7Eguido')
'http://www.python.org/%7Eguido'
```

   If you do not want that behavior, preprocess the *url* with |:urllib.parse.urlsplit:urlsplit()| and
   |:urllib.parse.urlunsplit:urlunsplit()|, removing possible *scheme* and *netloc* parts.

   Changed in version 3.5: Behaviour updated to match the semantics defined in
   *|index-4:⚓|* |:tools.ietf.org/html/rfc3986.html:RFC 3986|.

*urllib.parse.urldefrag:urllib.parse.urldefrag(url)*

   If *url* contains a fragment identifier, return a modified version of *url* with
   no fragment identifier, and the fragment identifier as a separate string.  If
   there is no fragment identifier in *url*, return *url* unmodified and an empty
   string.

   The return value is a |:glossary.txt/term-named-tuple:named tuple|, its items can be accessed by index or as
   named attributes:

   +--------------------+---------+---------------------------+------------------------+
   | Attribute          | Index   | Value                     | Value if not present   |
   |====================|=========|===========================|========================|
   | "url"              | 0       | URL with no fragment      | empty string           |
   +--------------------+---------+---------------------------+------------------------+
   | "fragment"         | 1       | Fragment identifier       | empty string           |
   +--------------------+---------+---------------------------+------------------------+

   See section |:urlparse-result-object:Structured Parse Results| for more information on the result
   object.

   Changed in version 3.2: Result is a structured object rather than a simple
   2-tuple.

*urllib.parse.unwrap:urllib.parse.unwrap(url)*

   Extract the url from a wrapped URL (that is, a string formatted as "
   <URL:scheme://host/path>", "<scheme://host/path>", "URL:scheme://host/path" or "
   scheme://host/path"). If *url* is not a wrapped URL, it is returned without
   changes.

*|parsing-ascii-encoded-bytes:⚓|* # parsing-ascii-encoded-bytes:Parsing ASCII
Encoded Bytes

The URL parsing functions were originally designed to operate on character
strings only. In practice, it is useful to be able to manipulate properly quoted
and encoded URLs as sequences of ASCII bytes. Accordingly, the URL parsing
functions in this module all operate on |:library/stdtypes.txt/bytes:bytes| and |:library/stdtypes.txt/bytearray:bytearray| objects in
addition to |:library/stdtypes.txt/str:str| objects.

If |:library/stdtypes.txt/str:str| data is passed in, the result will also contain only |:library/stdtypes.txt/str:str| data. If
|:library/stdtypes.txt/bytes:bytes| or |:library/stdtypes.txt/bytearray:bytearray| data is passed in, the result will contain only |:library/stdtypes.txt/bytes:bytes|
data.

Attempting to mix |:library/stdtypes.txt/str:str| data with |:library/stdtypes.txt/bytes:bytes| or |:library/stdtypes.txt/bytearray:bytearray| in a single function
call will result in a |:library/exceptions.txt/TypeError:TypeError| being raised, while attempting to pass in non-
ASCII byte values will trigger |:library/exceptions.txt/UnicodeDecodeError:UnicodeDecodeError|.

To support easier conversion of result objects between |:library/stdtypes.txt/str:str| and |:library/stdtypes.txt/bytes:bytes|, all
return values from URL parsing functions provide either an "encode()" method
(when the result contains |:library/stdtypes.txt/str:str| data) or a "decode()" method (when the result
contains |:library/stdtypes.txt/bytes:bytes| data). The signatures of these methods match those of the
corresponding |:library/stdtypes.txt/str:str| and |:library/stdtypes.txt/bytes:bytes| methods (except that the default encoding is "
'ascii'" rather than "'utf-8'"). Each produces a value of a corresponding type
that contains either |:library/stdtypes.txt/bytes:bytes| data (for "encode()" methods) or |:library/stdtypes.txt/str:str| data (for "
decode()" methods).

Applications that need to operate on potentially improperly quoted URLs that may
contain non-ASCII data will need to do their own decoding from bytes to
characters before invoking the URL parsing methods.

The behaviour described in this section applies only to the URL parsing
functions. The URL quoting functions use their own rules when producing or
consuming byte sequences as detailed in the documentation of the individual URL
quoting functions.

Changed in version 3.2: URL parsing functions now accept ASCII encoded byte
sequences

*|urlparse-result-object:⚓|* # structured-parse-results:Structured Parse Results

The result objects from the |:urllib.parse.urlparse:urlparse()|, |:urllib.parse.urlsplit:urlsplit()|  and |:urllib.parse.urldefrag:urldefrag()|
functions are subclasses of the |:library/stdtypes.txt/tuple:tuple| type. These subclasses add the
attributes listed in the documentation for those functions, the encoding and
decoding support described in the previous section, as well as an additional
method:

*urllib.parse.urllib.parse.SplitResult.geturl:urllib.parse.SplitResult.geturl()*

   Return the re-combined version of the original URL as a string. This may differ
   from the original URL in that the scheme may be normalized to lower case and
   empty components may be dropped. Specifically, empty parameters, queries, and
   fragment identifiers will be removed.

   For |:urllib.parse.urldefrag:urldefrag()| results, only empty fragment identifiers will be removed. For
   |:urllib.parse.urlsplit:urlsplit()| and |:urllib.parse.urlparse:urlparse()| results, all noted changes will be made to the URL
   returned by this method.

   The result of this method remains unchanged if passed back through the original
   parsing function:

```python
>>> from urllib.parse import urlsplit
>>> url = 'HTTP://www.Python.org/doc/#'
>>> r1 = urlsplit(url)
>>> r1.geturl()
'http://www.Python.org/doc/'
>>> r2 = urlsplit(r1.geturl())
>>> r2.geturl()
'http://www.Python.org/doc/'
```

The following classes provide the implementations of the structured parse
results when operating on |:library/stdtypes.txt/str:str| objects:

*urllib.parse.DefragResult:class urllib.parse.DefragResult(url, fragment)*

   Concrete class for |:urllib.parse.urldefrag:urldefrag()| results containing |:library/stdtypes.txt/str:str| data. The "encode()"
   method returns a |:urllib.parse.DefragResultBytes:DefragResultBytes| instance.

   New in version 3.2.

*urllib.parse.ParseResult:class urllib.parse.ParseResult(scheme, netloc, path, params, query, fragment)*

   Concrete class for |:urllib.parse.urlparse:urlparse()| results containing |:library/stdtypes.txt/str:str| data. The "encode()"
   method returns a |:urllib.parse.ParseResultBytes:ParseResultBytes| instance.

*urllib.parse.SplitResult:class urllib.parse.SplitResult(scheme, netloc, path, query, fragment)*

   Concrete class for |:urllib.parse.urlsplit:urlsplit()| results containing |:library/stdtypes.txt/str:str| data. The "encode()"
   method returns a |:urllib.parse.SplitResultBytes:SplitResultBytes| instance.

The following classes provide the implementations of the parse results when
operating on |:library/stdtypes.txt/bytes:bytes| or |:library/stdtypes.txt/bytearray:bytearray| objects:

*urllib.parse.DefragResultBytes:class urllib.parse.DefragResultBytes(url, fragment)*

   Concrete class for |:urllib.parse.urldefrag:urldefrag()| results containing |:library/stdtypes.txt/bytes:bytes| data. The "decode()"
   method returns a |:urllib.parse.DefragResult:DefragResult| instance.

   New in version 3.2.

*urllib.parse.ParseResultBytes:class urllib.parse.ParseResultBytes(scheme, netloc, path, params, query, fragment)*

   Concrete class for |:urllib.parse.urlparse:urlparse()| results containing |:library/stdtypes.txt/bytes:bytes| data. The "decode()"
   method returns a |:urllib.parse.ParseResult:ParseResult| instance.

   New in version 3.2.

*urllib.parse.SplitResultBytes:class urllib.parse.SplitResultBytes(scheme, netloc, path, query, fragment)*

   Concrete class for |:urllib.parse.urlsplit:urlsplit()| results containing |:library/stdtypes.txt/bytes:bytes| data. The "decode()"
   method returns a |:urllib.parse.SplitResult:SplitResult| instance.

   New in version 3.2.

# url-quoting:URL Quoting

The URL quoting functions focus on taking program data and making it safe for
use as URL components by quoting special characters and appropriately encoding
non-ASCII text. They also support reversing these operations to recreate the
original data from the contents of a URL component if that task isn’t already
covered by the URL parsing functions above.

*urllib.parse.quote:urllib.parse.quote(string, safe='/', encoding=None, errors=None)*

   Replace special characters in *string* using the "%xx" escape. Letters, digits,
   and the characters "'_.-~'" are never quoted. By default, this function is
   intended for quoting the path section of URL. The optional *safe* parameter
   specifies additional ASCII characters that should not be quoted — its default
   value is "'/'".

   *string* may be either a |:library/stdtypes.txt/str:str| or a |:library/stdtypes.txt/bytes:bytes|.

   Changed in version 3.7: Moved from *|index-5:⚓|* |:tools.ietf.org/html/rfc2396.html:RFC 2396| to *|index-6:⚓|*
   |:tools.ietf.org/html/rfc3986.html:RFC 3986| for quoting URL strings. “~” is now included in the set of unreserved
   characters.

   The optional *encoding* and *errors* parameters specify how to deal with non-
   ASCII characters, as accepted by the |:library/stdtypes.txt/str.encode:str.encode()| method. *encoding* defaults
   to "'utf-8'". *errors* defaults to "'strict'", meaning unsupported characters
   raise a |:library/exceptions.txt/UnicodeEncodeError:UnicodeEncodeError|. *encoding* and *errors* must not be supplied if *
   string* is a |:library/stdtypes.txt/bytes:bytes|, or a |:library/exceptions.txt/TypeError:TypeError| is raised.

   Note that "quote(string, safe, encoding, errors)" is equivalent to "
   quote_from_bytes(string.encode(encoding, errors), safe)".

   Example: "quote('/El Niño/')" yields "'/El%20Ni%C3%B1o/'".

*urllib.parse.quote_plus:urllib.parse.quote_plus(string, safe='', encoding=None, errors=None)*

   Like |:urllib.parse.quote:quote()|, but also replace spaces by plus signs, as required for quoting
   HTML form values when building up a query string to go into a URL. Plus signs in
   the original string are escaped unless they are included in *safe*.  It also
   does not have *safe* default to "'/'".

   Example: "quote_plus('/El Niño/')" yields "'%2FEl+Ni%C3%B1o%2F'".

*urllib.parse.quote_from_bytes:urllib.parse.quote_from_bytes(bytes, safe='/')*

   Like |:urllib.parse.quote:quote()|, but accepts a |:library/stdtypes.txt/bytes:bytes| object rather than a |:library/stdtypes.txt/str:str|, and does not
   perform string-to-bytes encoding.

   Example: "quote_from_bytes(b'a&\xef')" yields "'a%26%EF'".

*urllib.parse.unquote:urllib.parse.unquote(string, encoding='utf-8', errors='replace')*

   Replace "%xx" escapes by their single-character equivalent. The optional *
   encoding* and *errors* parameters specify how to decode percent-encoded
   sequences into Unicode characters, as accepted by the |:library/stdtypes.txt/bytes.decode:bytes.decode()| method.

   *string* must be a |:library/stdtypes.txt/str:str|.

   *encoding* defaults to "'utf-8'". *errors* defaults to "'replace'", meaning
   invalid sequences are replaced by a placeholder character.

   Example: "unquote('/El%20Ni%C3%B1o/')" yields "'/El Niño/'".

*urllib.parse.unquote_plus:urllib.parse.unquote_plus(string, encoding='utf-8', errors='replace')*

   Like |:urllib.parse.unquote:unquote()|, but also replace plus signs by spaces, as required for
   unquoting HTML form values.

   *string* must be a |:library/stdtypes.txt/str:str|.

   Example: "unquote_plus('/El+Ni%C3%B1o/')" yields "'/El Niño/'".

*urllib.parse.unquote_to_bytes:urllib.parse.unquote_to_bytes(string)*

   Replace "%xx" escapes by their single-octet equivalent, and return a |:library/stdtypes.txt/bytes:bytes|
   object.

   *string* may be either a |:library/stdtypes.txt/str:str| or a |:library/stdtypes.txt/bytes:bytes|.

   If it is a |:library/stdtypes.txt/str:str|, unescaped non-ASCII characters in *string* are encoded into
   UTF-8 bytes.

   Example: "unquote_to_bytes('a%26%EF')" yields "b'a&\xef'".

*urllib.parse.urlencode:urllib.parse.urlencode(query, doseq=False, safe='', encoding=None, errors=None, quote_via=quote_plus)*

   Convert a mapping object or a sequence of two-element tuples, which may contain
   |:library/stdtypes.txt/str:str| or |:library/stdtypes.txt/bytes:bytes| objects, to a percent-encoded ASCII text string.  If the
   resultant string is to be used as a *data* for POST operation with the
   |:library/urllib.request.txt/urllib.request.urlopen:urlopen()| function, then it should be encoded to bytes, otherwise it would
   result in a |:library/exceptions.txt/TypeError:TypeError|.

   The resulting string is a series of "key=value" pairs separated by "'&'"
   characters, where both *key* and *value* are quoted using the *quote_via*
   function.  By default, |:urllib.parse.quote_plus:quote_plus()| is used to quote the values, which means
   spaces are quoted as a "'+'" character and ‘/’ characters are encoded as "%2F",
   which follows the standard for GET requests ("application/x-www-form-urlencoded"
   ).  An alternate function that can be passed as *quote_via* is |:urllib.parse.quote:quote()|, which
   will encode spaces as "%20" and not encode ‘/’ characters.  For maximum control
   of what is quoted, use "quote" and specify a value for *safe*.

   When a sequence of two-element tuples is used as the *query* argument, the first
   element of each tuple is a key and the second is a value. The value element in
   itself can be a sequence and in that case, if the optional parameter *doseq* is
   evaluates to "True", individual "key=value" pairs separated by "'&'" are
   generated for each element of the value sequence for the key.  The order of
   parameters in the encoded string will match the order of parameter tuples in the
   sequence.

   The *safe*, *encoding*, and *errors* parameters are passed down to *quote_via*
   (the *encoding* and *errors* parameters are only passed when a query element is
   a |:library/stdtypes.txt/str:str|).

   To reverse this encoding process, |:urllib.parse.parse_qs:parse_qs()| and |:urllib.parse.parse_qsl:parse_qsl()| are provided in
   this module to parse query strings into Python data structures.

   Refer to |:library/urllib.request.txt/urllib-examples:urllib examples| to find out how urlencode method can be used for
   generating query string for a URL or data for POST.

   Changed in version 3.2: Query parameter supports bytes and string objects.

   New in version 3.5: *quote_via* parameter.

See also:

  *|index-7:⚓|*
  |:tools.ietf.org/html/rfc3986.html:RFC 3986| - Uniform Resource Identifiers
     This is the current standard (STD66). Any changes to urllib.parse module should
     conform to this. Certain deviations could be observed, which are mostly for
     backward compatibility purposes and for certain de-facto parsing requirements as
     commonly observed in major browsers.

  *|index-8:⚓|*
  |:tools.ietf.org/html/rfc2732.html:RFC 2732| - Format for Literal IPv6 Addresses in URL’s.
     This specifies the parsing requirements of IPv6 URLs.

  *|index-9:⚓|*
  |:tools.ietf.org/html/rfc2396.html:RFC 2396| - Uniform Resource Identifiers (URI): Generic Syntax
     Document describing the generic syntactic requirements for both Uniform Resource
     Names (URNs) and Uniform Resource Locators (URLs).

  *|index-10:⚓|*
  |:tools.ietf.org/html/rfc2368.html:RFC 2368| - The mailto URL scheme.
     Parsing requirements for mailto URL schemes.

  *|index-11:⚓|*
  |:tools.ietf.org/html/rfc1808.html:RFC 1808| - Relative Uniform Resource Locators
     This Request For Comments includes the rules for joining an absolute and a
     relative URL, including a fair number of “Abnormal Examples” which govern the
     treatment of border cases.

  *|index-12:⚓|*
  |:tools.ietf.org/html/rfc1738.html:RFC 1738| - Uniform Resource Locators (URL)
     This specifies the formal syntax and semantics of absolute URLs.



